{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12dc073f-2824-47d7-9f32-75f3b800caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.0 pandas-2.2.2 tzdata-2024.1\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.1.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.2 pillow-10.4.0 pyparsing-3.1.2 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c2c9f1-2176-4f56-ae8e-77a3db7b9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237ad4e7-deaf-48ae-ad68-01ce430463a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_create_columns(df, column_name):\n",
    "    df[column_name] = df[column_name].astype('string')\n",
    "    #fill with UnKnown all NaN\n",
    "    df[column_name] = df[column_name].fillna('UnKnown')\n",
    "    # Split the specified column by comma and create a set of all unique values\n",
    "    all_values = []\n",
    "    for row in df[column_name]:\n",
    "      if row is not None:\n",
    "        values=row.split(',')\n",
    "        for val in values:\n",
    "          if val not in all_values:\n",
    "            all_values.append(val)\n",
    "\n",
    "    # Create new columns for each unique value, initialized with False\n",
    "    for value in all_values:\n",
    "        df[column_name+\"_\"+value.strip()] = False\n",
    "\n",
    "    # Iterate through each row and set the appropriate columns to True\n",
    "    for index, row in df.iterrows():\n",
    "        values = row[column_name].split(',')\n",
    "        for value in values:\n",
    "            df.at[index, column_name+\"_\"+value.strip()] = True\n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77464142-99e3-40c1-869f-f42ff1984c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_df = pd.read_csv('TMDB_tv_dataset_v3.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5873a86c-da1d-4335-a704-59d4ba89756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = org_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c98867-0165-419a-a920-ab36b98332cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the columns to date base on the content of list_date_columns\n",
    "list_date_columns = ['first_air_date', 'last_air_date']\n",
    "for column in list_date_columns:\n",
    "    df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "\n",
    "#remove all rows that first_air_date is older that 2015\n",
    "df = df[df['first_air_date'] >= '2015-01-01']\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#remove all rows that first_air_date is after 2024-01-01\n",
    "df = df[df['first_air_date'] <= '2024-01-01']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9d1d52-5373-43f7-9b82-33ab2af83e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all columns that has NaN more than 66% of the total df length\n",
    "nan_columns = df.columns[df.isna().mean() > 0.66]\n",
    "df = df.drop(nan_columns, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c55811-c63c-4741-9fe1-e3bd31fe15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove backdrop_path column , not relevant\n",
    "df = df.drop(['backdrop_path'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c245c1-d4db-4a84-84e8-6f8432575b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If last_air_date is NaN , put todays date in it\n",
    "df['last_air_date'] = df['last_air_date'].fillna(pd.to_datetime('today'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ce8f29-6782-4850-84d5-54bba7ef3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove poster_path , not relevant\n",
    "df = df.drop(['poster_path'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6086756c-0647-4e03-865d-6480a44f7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the columns to string base on the content of list_columns\n",
    "list_columns = ['name','original_language','original_name','languages','networks','origin_country','spoken_languages','genres','overview','homepage','production_companies','production_countries']\n",
    "for column in list_columns:\n",
    "    df[column] = df[column].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f1bdc6-3368-4a83-b87a-aacb6469a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the columns to category base on the content of list_category_columns\n",
    "list_category_columns = ['original_language','adult','status','in_production','type']\n",
    "for column in list_category_columns:\n",
    "    df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf26fc9-e0dc-468a-92d8-5ba575dfd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the columns to int base on the content of list_int_columns\n",
    "list_int_columns = ['number_of_seasons','number_of_episodes','vote_count']\n",
    "for column in list_int_columns:\n",
    "    df[column] = df[column].astype(int)\n",
    "\n",
    "#Convert the columns to float base on the content of list_float_columns\n",
    "list_float_columns = ['vote_average', 'popularity']\n",
    "for column in list_float_columns:\n",
    "    df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9dca023-8098-448e-9d9e-9e8034cd01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by comma and create bool columns\n",
    "df = split_and_create_columns(df, 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5784023-3626-4274-ae4e-02cec13e3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all bool type columns to category\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'bool':\n",
    "        df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68805b3e-3511-467f-bf95-b5dcb39d00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only the top 10 Networks from columns networks\n",
    "cols = df['networks'].value_counts()[:10].index\n",
    "df['networks'] = df['networks'].apply(lambda x: x if x in cols else 'Other')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21bf8be8-e1b5-4f00-aa40-4c0ea32ea028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert networks to category\n",
    "df['networks'] = df['networks'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e2565c-f97e-4eb8-b055-3a3b3388d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove from homepage the sctings: http:// , https://\n",
    "df['homepage'] = df['homepage'].str.replace('http://', '')\n",
    "df['homepage'] = df['homepage'].str.replace('https://', '')\n",
    "#split homepage by \"/\" anf get only the first element\n",
    "df['homepage'] = df['homepage'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0a5957-7e48-45f3-aad4-1aaaa079a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only the top 10 homepage from columns homepage\n",
    "#take the top 10\n",
    "cols = df['homepage'].value_counts()[:10].index\n",
    "df['homepage'] = df['homepage'].apply(lambda x: x if x in cols else 'Other')\n",
    "df['homepage'] = df['homepage'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2db54d-01c2-4c76-9a3a-e25db116b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the column production_companies\n",
    "df = df.drop(['production_companies'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89710700-2642-4ece-89ac-53dea7aebce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new string base DF base on the columns: overview,homepage,original_name,languages,spoken_languages,production_countries\n",
    "#df_string = df[['overview', 'homepage', 'original_name', 'languages', 'spoken_languages', 'production_countries']]\n",
    "#df.drop(['overview', 'homepage', 'original_name', 'languages', 'spoken_languages', 'production_countries'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fe2beb-2420-4528-aa8a-ebb2785343db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tv_flat_file.csv')\n",
    "df.to_pickle('tv_flat_file.pkl')\n",
    "#df_string.to_csv('tv_flat_file_str.csv')\n",
    "#df_string.to_pickle('tv_flat_file_str.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "567af921-e4e2-423a-af3f-a7379caa8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column total_brodcast_months \n",
    "#df['total_broadcast_months'] = (df['last_air_date'] - df['first_air_date']).dt.days / 30\n",
    "#df.drop(['first_air_date','last_air_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e156c17-2b5f-4830-9431-0556db005357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove name - not relevant for prediction\n",
    "#df.drop(['name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d54ace47-bdac-4a04-8561-5b2cbdb6dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all categories to number\n",
    "#df = df.apply(lambda x: x.cat.codes if x.dtype.name == 'category' else x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
